---
layout : article
title:  강화학습에 대한 기본적인 개념
aside:
  toc: true
tags: MachineLearning
category : MachineLearning
author: melonicedlatte
published : True
# cover : /assets/images/logo/chihuahua.jpg
key : 2019-04-20-091700
---

## 강화학습의 개념

<iframe width="665" height="554" src="https://www.youtube.com/embed/3TciIbGUYUg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

강화학습으로 자동차를 제어하는 영상이다. 어떻게 자동차가 자기 스스로 주행하는 방법을 학습할 수 있을까? (실제 자동차 운전에서는 안전 문제때문에 강화 학습을 잘 적용하지 않는 것으로 알고 있다. 영상은 게임이기 때문에, 수없이 많은 시도를 할 수 있어 강화학습이 가능하다.)

아래에서 강화학습에 대하여 알아보자.

### 스키너의 강화 연구

스키너의 강화 연구는 강화학습 이야기가 나오면 항상 나오는 이야기입니다. 스키너의 강화 연구는 아래와 같은 이야기입니다.

1. 굶긴 쥐를 지렛대를 누르게 되면 먹이가 나오게 되는 상자에 넣는다.
2. 아무 것도 모르는 쥐가 이곳 저곳 돌아다니다가 지렛대를 눌러 먹이를 받는다.
3. 지렛대의 원리를 파악하지 못한 쥐는 왜 나오는지 모르고 다시 아무곳이나 돌아다닌다.
4. 돌아다니다가 지렛대를 계속 누르면서 먹이를 받고, 지렛대와 먹이와의 상관관계를 학습하게 된다.

### 지도학습? 비지도학습? 강화학습?

- 지도학습 : 정답을 알고 있는 데이터로 컴퓨터를 학습.
- 비지도학습 : 정답이 없는 데이터를 학습.
- 강화학습 : 보상(행위자가 선택한 행동에 대한 환경의 반응)을 통해 학습. 자신의 행동과 행동의 결과를 보상을 통해 어떠한 행동을 해야 할 지 학습.

## 어디에 강화 학습을 적용할 수 있을까

### 순차적 행동 결정 문제

`순차적 행동 결정 문제`란 결정을 순차적으로 내려야 하는 문제에 적용된다. 체스나 장기같은 게임은 한 말이 움직이고 나서야 그 다음에 다음 말을 움직일 수 있는 순차적 행동 결정 문제 중 한 가지이다.

#### 순차적 행동 결정 문제의 구성 요소

강화학습을 통해 학습하는 행위자, 컴퓨터를 agent 라고 한다.

- 상태 : agent의 정적, 동적인 정보
  - 예) 축구 선수 위치, 축구 공의 속도
- 행동 : agent가 취할 수 있는 행동
  - 예) 축구 선수의 이동, 축구 선수의 슈팅 여부
- 보상 : 행위를 했을 때, 얻을 수 있는 값. 보상이 최대가 되게 하는 정책을 찾아야 함.  
  - 예) 득점시 100점, 실책시 -10점 등
- 정책 : agent가 보상을 얻으려면 행동을 해야 한다. agent는 주어진 상태에 어떤 행동을 해야할 지 알야아 한다. 즉, agent의 모든 상태에 대해 agent가 어떤 행동을 해야 하는지 정해 놓은 것.

이러한 4가지 구성 요소들을 `MDP`라고 합니다.
